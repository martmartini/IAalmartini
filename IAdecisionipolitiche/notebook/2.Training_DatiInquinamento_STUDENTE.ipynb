{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AJp7knAzKP8B"},"outputs":[],"source":["# moduli usati\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","import pandas as pd\n","import numpy  as np"]},{"cell_type":"markdown","metadata":{"id":"zPz9HtwVKP8C"},"source":["# Leggiamo i dati di APPA\n","\n","Come nella precedente lezione carichiamo i dati di APPA, selezioniamo la stazione e calcoliamo i valori medi giornalieri per ogni inquinante in modo da ottenere la tabella pivot usata per il calcolo della correlazione nella scorsa lezione."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"5DMseL9LL-ND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_folder = Path(\"/content/drive/MyDrive/data\")\n","appa = pd.read_csv(\n","    data_folder / \"DataSet_APPA/processed/appa_data.csv\", parse_dates=[\"Data\"]\n",")\n","# definiamo la stazione da analizzare\n","station = \"Piana Rotaliana\"\n","exp_data = appa.loc[(appa.Stazione == station)].set_index(\"Data\").groupby([\"Inquinante\"]).resample(\"D\").mean(\"Valore\").reset_index()\n","# converto i nomi degli inquinanti in codici (formule chimiche o abbreviazioni)\n","exp_data[\"Inquinante\"] = exp_data.Inquinante.map(\n","    {\"PM10\": \"PM10\", \"Biossido di Azoto\": \"NO2\", \"Ozono\": \"O3\"}\n",")\n","# converto il dataframe in una tabella pivot (formato wide) e ordino i dati per data\n","exp_data = exp_data.pivot_table(\n","    index=\"Data\", columns=\"Inquinante\", values=\"Valore\"\n",").sort_index()\n","\n","exp_data"],"metadata":{"id":"BJSIgy_HNPKK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lvfXcxvKP8P"},"source":["# Previsione del valore medio giornaliero di PM10 in base ai dati APPA\n","\n","In base ai dati del nostro dataframe possiamo riuscire a prevedere il valore medio giornaliero di un inquinante, ad esempio il PM10?\n","\n","I modelli di ML basati sulle regressioni possono essere applicati per prevedere la variazione di un valore nel tempo. Alla base di questi modelli ci sono i dati.\n","\n","Proviamo a capire come costruire un set di dati a partire dal nostro dataset APPA. L'obiettivo è prevedere il valore medio di PM10 in base ai valori dei giorni precedenti.\n","\n","\n"]},{"cell_type":"markdown","source":["## Costruzione del dato\n","\n","Quali sono i dati e i valori che potrebbero essere utili? Sicuramente i valori di PM10 dei giorni precedenti o il valore medio della settimana precedente.\n","\n","Il codice seguente permette di aggiungere al dataframe:\n","* una feature (colonna) di dati sfasati di un certo intervallo temporale, ad esempio 1 giorno,\n","`pollutant_series.shift(1).rename(\"inquinante_ritardato_1d\"),`\n","* una feature (colonna) di valori medi `.mean()`, massimi `.max()` o minimi `.min()` della settimana precedente (7 giorni).\n","`pollutant_series.shift(1).rolling(7).mean().rename(\"inquinante_medio_settimana\"),`\n","* informazioni sulla data come ad esempio giorno (day), settimana (week), mese (month), anno (year)\n","`pd.Series(pollutant_series.index.year, index=pollutant_series.index).rename(\"year\")`"],"metadata":{"id":"7yiHJdKdBk20"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCJ_n7zwKP8S"},"outputs":[],"source":["pollutant = \"PM10\"\n","pollutant_series = exp_data[pollutant]\n","# mi assicuro di avere i dati ordinati per data\n","pollutant_series = pollutant_series.sort_index()\n","\n","\n","lagged_df = pd.concat([\tpollutant_series,\n","\t\t\t\t\t\tpollutant_series.shift(1).rename(\"inquinante_ritardato_1d\"),\n","\t\t\t\t\t\tpollutant_series.shift(1).rolling(7).mean().rename(\"inquinante_medio_settimana\"),\n","\t\t\t\t\t\tpd.Series(pollutant_series.index.year,\n","\t\t\t\t\t\tindex=pollutant_series.index).rename(\"year\"),\n","\t\t\t\t\t\tpd.Series(pollutant_series.index.day,\n","\t\t\t\t\t\tindex=pollutant_series.index).rename(\"day\"),\n","\t\t\t\t\t\tpd.Series(pollutant_series.index.month,\n","\t\t\t\t\t\tindex=pollutant_series.index).rename(\"month\")\n","\t\t\t\t\t\t],\n","\t\t\t\t\taxis=\"columns\",)\n","\n","lagged_df.head(10)\n","\n","#lagged_df.tail(10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"St0nsk2bKP8Y"},"outputs":[],"source":["# controllo le dimensioni\n","exp_data.shape, lagged_df.shape\n"]},{"cell_type":"markdown","metadata":{"id":"NhL0AO4wKP8Z"},"source":["## Separazione colonna target e suddivisione dei dati (data splitting)"]},{"cell_type":"markdown","source":["La colonna PM10 sono i valori medi giornalieri che dobbiamo prevedere. Le altre colonne costituiscono la tabella di input del modello. Dunque **separiamo** la colonna obiettivo dei PM10 dalle altre colonne che contengono le features."],"metadata":{"id":"kYyHSi03w9Mi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3B8WGK-hKP8Y"},"outputs":[],"source":["\n","# seleziono i dati da utilizzare per addestrare il modello\n","# X rappresenta le variabili in input\n","# y rappresenta la variabile che vogliamo predire\n","\n","X = lagged_df.dropna().drop(columns=pollutant)\n","y = lagged_df.dropna()[pollutant]\n","X.shape, y.shape"]},{"cell_type":"markdown","source":["I dati vengono suddivisi in due set.\n","\n","L'**80%** costituisce il dataset (matrice più vettore) su cui **allenare** il modello.\n","\n","Il restante 20% lo teniamo come test. Utilizziamo il 20% della matrice dei dati costruita da noi come **input** per prevedere i valori di PM10. Questi valori possono essere **confrontati** con il vettore di dati di PM10 misurati per capire la performance del modello."],"metadata":{"id":"oA96BV-PaeV9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkeiWuJUKP8Z"},"outputs":[],"source":["# shuffle False, quindi uso il primo 80% di dati per training, e il restante per test\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, shuffle=False\n",")\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"markdown","source":["## Training del modello\n","\n","Utilizziamo un algoritmo (Random Forest Regressor) basato sulla regressione. Con il metodo fit andiamo a \"creare\" il modello che poi useremo per prevedere il valore di PM10 del giorno sucessivo."],"metadata":{"id":"cvbIgQXaylet"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-ZdA6-yKP8Z"},"outputs":[],"source":["model = RandomForestRegressor(random_state=42)\n","# alleno il modello sugli ultimi 10000 punti di training\n","model.fit(X_train, y_train)"]},{"cell_type":"markdown","source":["## Previsione sul test\n","\n","Andiamo a prevedere il PM10 sul set di dati per il test (20%)."],"metadata":{"id":"8VlKnmTszPOt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6uDnRM8KP8c"},"outputs":[],"source":["y_pred = y_test.copy()\n","\n","y_pred[:] = model.predict(X_test)\n","y_pred\n","\n","test = pd.merge(\n","    y_test, y_pred, left_index=True, right_index=True, suffixes=(\"_true\", \"_pred\")\n",")\n","test"]},{"cell_type":"markdown","source":["Grafichiamo i dati previsti e i misurati per confrontarli."],"metadata":{"id":"3PgAYWnh08qP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gs-jXkIMKP8e"},"outputs":[],"source":["test.loc[\"2022-01-01\":\"2022-12-31\", [\"PM10_true\", \"PM10_pred\"]].plot(figsize=(15, 5), title=\"PM10\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsWwVJyuKP8f"},"outputs":[],"source":["test[\"2023-01-03\":\"2023-05-31\"].plot(figsize=(15, 5), marker=\"*\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ESs7wWcKP8f"},"outputs":[],"source":["ax = test.plot.scatter(x=\"PM10_true\", y=\"PM10_pred\", alpha=0.5, marker=\".\")\n","#ax.plot([0, 100], [0, 100], c=\"C1\")\n"]},{"cell_type":"markdown","source":["Valutiamo numericamente il coefficiente di determinazione (R^2).\n","\n"],"metadata":{"id":"N7Th97vx1tFY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W68wy6ZeKP8a"},"outputs":[],"source":["# valuto il modello (coefficiente di determinazione)\n","model.score(X_train, y_train), model.score(X_test, y_test)"]},{"cell_type":"markdown","source":["Per decidere quale colonna mantenere può essere utile capire quale features vengono usate maggiormente dal modello. Esiste un parametro, la feature importance, che può essere graficato come riportato di seguito."],"metadata":{"id":"txnNPgsS9w0B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyrLdzYdKP8f"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","forest_importances = pd.Series(model.feature_importances_, index=X.columns)\n","\n","fig, ax = plt.subplots()\n","forest_importances.plot.bar(ax=ax)\n","ax.set_title(\"Feature importances using MDI\")\n","ax.set_ylabel(\"Mean decrease in impurity\")\n","fig.tight_layout()"]},{"cell_type":"markdown","source":["# Osservazioni\n","\n","Riporta le tue osservazioni\n","\n"],"metadata":{"id":"8aReK2_mKP8g"}},{"cell_type":"markdown","source":["## Possibili domande  e spunti\n","*   Quali colonne abbiamo usato?\n","*   Ci sono altri dati che potrebbero essere utlizzati?"],"metadata":{"id":"2se9nRRtbS4k"}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[{"file_id":"10JyLLi9OS5cntQXP4sW3VREoF5JrbY3b","timestamp":1710147381297},{"file_id":"1LiqjOm_CO8ckxbUXrDsgTtzlokOQeVar","timestamp":1710077061942}]}},"nbformat":4,"nbformat_minor":0}